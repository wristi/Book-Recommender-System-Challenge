{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "721bc9f0",
   "metadata": {},
   "source": [
    "Next key step in building CF-based recommendation systems is to generate user-item ratings matrix from the ratings table.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434c3c61",
   "metadata": {},
   "source": [
    "Using SKlearn, we are going to use a variety of functions to find similarity, predict, and recommend different books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94875c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05f61bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from surprise.model_selection import cross_validate\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "import re\n",
    "import surprise\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0f957e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('BX-Book-Ratings.csv', encoding='ISO-8859–1',on_bad_lines='skip',quotechar='\"',sep=\";\",escapechar= \"\\\\\")\n",
    "books = pd.read_csv('BX-Books.csv', encoding='ISO-8859–1',on_bad_lines='skip',quotechar='\"',sep=\";\",escapechar= \"\\\\\")\n",
    "users = pd.read_csv('BX-Users.csv', encoding='ISO-8859–1',on_bad_lines='skip',quotechar='\"',sep=\";\",escapechar= \"\\\\\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23d3329b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['User-ID', 'ISBN', 'Book-Rating'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(ratings.shape)\n",
    "ratings.columns\n",
    "\n",
    "\n",
    "\n",
    "#print(books.shape)\n",
    "#print(users.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14fffe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove implicit data\n",
    "drop_duplicate_ratings = ratings.drop_duplicates().dropna()\n",
    "explicit_book_ratings = drop_duplicate_ratings[drop_duplicate_ratings['Book-Rating'] > 0]\n",
    "\n",
    "\n",
    "#Merge Users & Ratings dataset\n",
    "reviews_and_users = pd.merge(left=explicit_book_ratings,right= books, how = 'inner').merge(users.dropna(), how = 'inner')\n",
    "reviews_and_users = reviews_and_users.drop_duplicates()\n",
    "\n",
    "#Dataset Cleaning\n",
    "reviews_and_users = reviews_and_users.drop(columns = ['Location','Image-URL-S','Image-URL-M','Image-URL-L'])\n",
    "reviews_and_users = reviews_and_users.rename(columns={\"User-ID\": \"UserID\", \"Book-Rating\": \"BookRating\", \"Book-Author\": \"BookAuthor\", \"Book-Title\": \"BookTitle\",\"Year-Of-Publication\": \"PublicationYear\"})\n",
    "reviews_and_users['BookAuthor'] = reviews_and_users['BookAuthor'].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0280b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ddeb9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>BookRating</th>\n",
       "      <th>BookTitle</th>\n",
       "      <th>BookAuthor</th>\n",
       "      <th>PublicationYear</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "      <td>Help!: Level 1</td>\n",
       "      <td>Philip Prowse</td>\n",
       "      <td>1999</td>\n",
       "      <td>Cambridge University Press</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "      <td>The Amsterdam Connection : Level 4 (Cambridge ...</td>\n",
       "      <td>Sue Leather</td>\n",
       "      <td>2001</td>\n",
       "      <td>Cambridge University Press</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16877</td>\n",
       "      <td>038550120X</td>\n",
       "      <td>9</td>\n",
       "      <td>A Painted House</td>\n",
       "      <td>John Grisham</td>\n",
       "      <td>2001</td>\n",
       "      <td>Doubleday</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16877</td>\n",
       "      <td>034539657X</td>\n",
       "      <td>7</td>\n",
       "      <td>Dark Rivers of the Heart</td>\n",
       "      <td>Dean R. Koontz</td>\n",
       "      <td>1995</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16877</td>\n",
       "      <td>0743211383</td>\n",
       "      <td>3</td>\n",
       "      <td>Dreamcatcher</td>\n",
       "      <td>Stephen King</td>\n",
       "      <td>2001</td>\n",
       "      <td>Scribner</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269625</th>\n",
       "      <td>276660</td>\n",
       "      <td>0583307841</td>\n",
       "      <td>8</td>\n",
       "      <td>ROBOT RACE (MICRO ADV 6)</td>\n",
       "      <td>David Antony Kroft</td>\n",
       "      <td>1985</td>\n",
       "      <td>HarperCollins Publishers</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269626</th>\n",
       "      <td>276664</td>\n",
       "      <td>0004703723</td>\n",
       "      <td>9</td>\n",
       "      <td>Dictionary Of Economics-2Nd Ed</td>\n",
       "      <td>Christopher Pass</td>\n",
       "      <td>1991</td>\n",
       "      <td>Trafalgar Square</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269627</th>\n",
       "      <td>276664</td>\n",
       "      <td>0140136908</td>\n",
       "      <td>7</td>\n",
       "      <td>History of Economic Thought (Penguin Economics)</td>\n",
       "      <td>William J. Barber</td>\n",
       "      <td>1992</td>\n",
       "      <td>Penguin USA</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269628</th>\n",
       "      <td>276664</td>\n",
       "      <td>0631189629</td>\n",
       "      <td>9</td>\n",
       "      <td>British Social Policy Since 1945 (Making Conte...</td>\n",
       "      <td>Howard Glennerster</td>\n",
       "      <td>1996</td>\n",
       "      <td>Blackwell Publishers</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269629</th>\n",
       "      <td>276664</td>\n",
       "      <td>0747205051</td>\n",
       "      <td>7</td>\n",
       "      <td>Murderous Women: True Talesof W</td>\n",
       "      <td>Frank Jones</td>\n",
       "      <td>1992</td>\n",
       "      <td>Headline</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>269630 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        UserID        ISBN  BookRating  \\\n",
       "0       276729  052165615X           3   \n",
       "1       276729  0521795028           6   \n",
       "2        16877  038550120X           9   \n",
       "3        16877  034539657X           7   \n",
       "4        16877  0743211383           3   \n",
       "...        ...         ...         ...   \n",
       "269625  276660  0583307841           8   \n",
       "269626  276664  0004703723           9   \n",
       "269627  276664  0140136908           7   \n",
       "269628  276664  0631189629           9   \n",
       "269629  276664  0747205051           7   \n",
       "\n",
       "                                                BookTitle          BookAuthor  \\\n",
       "0                                          Help!: Level 1       Philip Prowse   \n",
       "1       The Amsterdam Connection : Level 4 (Cambridge ...         Sue Leather   \n",
       "2                                         A Painted House        John Grisham   \n",
       "3                                Dark Rivers of the Heart      Dean R. Koontz   \n",
       "4                                            Dreamcatcher        Stephen King   \n",
       "...                                                   ...                 ...   \n",
       "269625                           ROBOT RACE (MICRO ADV 6)  David Antony Kroft   \n",
       "269626                     Dictionary Of Economics-2Nd Ed    Christopher Pass   \n",
       "269627    History of Economic Thought (Penguin Economics)   William J. Barber   \n",
       "269628  British Social Policy Since 1945 (Making Conte...  Howard Glennerster   \n",
       "269629                    Murderous Women: True Talesof W         Frank Jones   \n",
       "\n",
       "        PublicationYear                   Publisher   Age  \n",
       "0                  1999  Cambridge University Press  16.0  \n",
       "1                  2001  Cambridge University Press  16.0  \n",
       "2                  2001                   Doubleday  37.0  \n",
       "3                  1995            Ballantine Books  37.0  \n",
       "4                  2001                    Scribner  37.0  \n",
       "...                 ...                         ...   ...  \n",
       "269625             1985    HarperCollins Publishers  15.0  \n",
       "269626             1991            Trafalgar Square  31.0  \n",
       "269627             1992                 Penguin USA  31.0  \n",
       "269628             1996        Blackwell Publishers  31.0  \n",
       "269629             1992                    Headline  31.0  \n",
       "\n",
       "[269630 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_and_users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b56661d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63d203f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def popular_ratings(ratings, user_threshold=200, rating_threshold=200, book_threshold=1):\n",
    "    counts_users = ratings.UserID.value_counts()\n",
    "    counts_ratings = ratings.BookRating.value_counts()\n",
    "    sample_ratings = ratings[ratings['UserID'].isin(counts_users[counts_users >= user_threshold].index)]\n",
    "    sample_ratings = sample_ratings[ratings['BookRating'].isin(counts_ratings[counts_ratings >= rating_threshold].index)]\n",
    "    isbn_group = sample_ratings.groupby('ISBN', as_index=False)['BookRating'].count()\n",
    "    sample_ratings = sample_ratings[sample_ratings.ISBN.isin(list(isbn_group[isbn_group.BookRating > book_threshold].ISBN.values))]\n",
    "    return sample_ratings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ee410bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4047, 8)\n",
      "(26, 1841)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6n/zr58hzps4cz7_n89qjnrzb5w0000gr/T/ipykernel_98360/3535787043.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  sample_ratings = sample_ratings[ratings['BookRating'].isin(counts_ratings[counts_ratings >= rating_threshold].index)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ISBN</th>\n",
       "      <th>0001056107</th>\n",
       "      <th>002026478X</th>\n",
       "      <th>0060002050</th>\n",
       "      <th>006000441X</th>\n",
       "      <th>0060004606</th>\n",
       "      <th>0060004622</th>\n",
       "      <th>006000469X</th>\n",
       "      <th>0060004746</th>\n",
       "      <th>0060008865</th>\n",
       "      <th>0060011904</th>\n",
       "      <th>...</th>\n",
       "      <th>1854710443</th>\n",
       "      <th>1855385074</th>\n",
       "      <th>1878448900</th>\n",
       "      <th>1890862185</th>\n",
       "      <th>1890862290</th>\n",
       "      <th>189205101X</th>\n",
       "      <th>1892065487</th>\n",
       "      <th>1895565014</th>\n",
       "      <th>1902852427</th>\n",
       "      <th>1932112138</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23872</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56399</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60244</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63714</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69078</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76626</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78973</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93047</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95359</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98391</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100906</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101851</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114368</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123883</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129074</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153662</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171118</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177458</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185233</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189334</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197659</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204864</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235105</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248718</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257204</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26 rows × 1841 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ISBN    0001056107  002026478X  0060002050  006000441X  0060004606  \\\n",
       "UserID                                                               \n",
       "16795          0.0         0.0         0.0         0.0         0.0   \n",
       "23872          0.0         0.0         0.0         0.0         0.0   \n",
       "56399          0.0         0.0         0.0         0.0         0.0   \n",
       "60244          0.0         0.0         0.0         0.0         0.0   \n",
       "63714          0.0         0.0         0.0         0.0         0.0   \n",
       "69078          0.0         0.0         0.0         0.0         0.0   \n",
       "76626          0.0         0.0         0.0         0.0         0.0   \n",
       "78973          0.0         0.0         0.0         0.0         0.0   \n",
       "93047          8.0         0.0         0.0         0.0         0.0   \n",
       "95359          8.0        10.0         0.0         0.0         0.0   \n",
       "98391          0.0         0.0         8.0         9.0         8.0   \n",
       "100906         0.0         0.0         0.0         0.0         0.0   \n",
       "101851         0.0         0.0         0.0         0.0         0.0   \n",
       "114368         0.0         0.0         5.0         0.0         0.0   \n",
       "123883         0.0         0.0         0.0         0.0         0.0   \n",
       "129074         0.0         0.0         0.0         0.0         0.0   \n",
       "153662         0.0         0.0         0.0         0.0         0.0   \n",
       "171118         0.0         0.0         0.0         0.0         0.0   \n",
       "177458         0.0         0.0         0.0         0.0         0.0   \n",
       "185233         0.0         0.0         0.0         0.0         0.0   \n",
       "189334         0.0         0.0         0.0         0.0         0.0   \n",
       "197659         0.0         0.0         0.0         0.0         0.0   \n",
       "204864         0.0         0.0         0.0         0.0         0.0   \n",
       "235105         0.0         0.0         0.0         9.0         9.0   \n",
       "248718         0.0        10.0         0.0         0.0         0.0   \n",
       "257204         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "ISBN    0060004622  006000469X  0060004746  0060008865  0060011904  ...  \\\n",
       "UserID                                                              ...   \n",
       "16795          0.0         0.0         0.0         0.0         0.0  ...   \n",
       "23872          0.0         0.0         0.0         0.0         0.0  ...   \n",
       "56399          0.0         0.0         0.0         0.0         0.0  ...   \n",
       "60244          0.0         0.0         0.0         0.0         0.0  ...   \n",
       "63714          0.0         0.0         0.0         0.0         0.0  ...   \n",
       "69078          0.0         0.0         0.0         0.0         0.0  ...   \n",
       "76626          0.0         0.0         0.0         0.0         0.0  ...   \n",
       "78973          0.0         0.0         0.0         0.0         0.0  ...   \n",
       "93047          0.0         0.0         0.0         0.0         0.0  ...   \n",
       "95359          0.0         0.0         0.0         0.0         0.0  ...   \n",
       "98391          8.0         8.0        10.0         9.0         9.0  ...   \n",
       "100906         0.0         0.0         0.0         0.0         0.0  ...   \n",
       "101851         0.0         0.0         0.0         0.0         0.0  ...   \n",
       "114368         0.0         0.0         0.0         0.0         0.0  ...   \n",
       "123883         0.0         0.0         0.0         0.0         0.0  ...   \n",
       "129074         0.0         0.0         0.0         0.0         0.0  ...   \n",
       "153662         0.0         0.0         0.0         0.0         0.0  ...   \n",
       "171118         0.0         0.0         0.0         0.0         0.0  ...   \n",
       "177458         0.0         0.0         0.0         0.0         0.0  ...   \n",
       "185233         0.0         0.0         0.0         0.0         0.0  ...   \n",
       "189334         0.0         0.0         0.0         0.0         0.0  ...   \n",
       "197659         0.0         0.0         0.0         0.0         0.0  ...   \n",
       "204864         0.0         0.0         0.0         0.0         0.0  ...   \n",
       "235105         8.0         7.0         7.0         7.0         8.0  ...   \n",
       "248718         0.0         0.0         0.0         0.0         0.0  ...   \n",
       "257204         0.0         0.0         0.0         0.0         0.0  ...   \n",
       "\n",
       "ISBN    1854710443  1855385074  1878448900  1890862185  1890862290  \\\n",
       "UserID                                                               \n",
       "16795          0.0         0.0         0.0         0.0         0.0   \n",
       "23872          0.0         0.0         0.0         0.0         0.0   \n",
       "56399         10.0        10.0         0.0         0.0         0.0   \n",
       "60244          0.0         0.0         8.0         0.0         0.0   \n",
       "63714         10.0         0.0         0.0         0.0         0.0   \n",
       "69078          0.0         0.0         0.0         0.0         0.0   \n",
       "76626          0.0         0.0         0.0         0.0         0.0   \n",
       "78973          0.0         0.0         0.0         0.0         0.0   \n",
       "93047          0.0         0.0         0.0         0.0         0.0   \n",
       "95359          0.0         0.0         0.0         0.0         0.0   \n",
       "98391          0.0         0.0         0.0         9.0         8.0   \n",
       "100906         0.0         0.0         0.0         0.0         0.0   \n",
       "101851         0.0         0.0         0.0         0.0         0.0   \n",
       "114368         0.0         0.0         0.0         0.0         0.0   \n",
       "123883         0.0         0.0         0.0         0.0         0.0   \n",
       "129074         0.0         0.0         0.0         0.0         0.0   \n",
       "153662         0.0         0.0         9.0         0.0         0.0   \n",
       "171118         0.0         0.0         0.0         0.0         0.0   \n",
       "177458         0.0         8.0         0.0         0.0         0.0   \n",
       "185233         0.0         0.0         0.0         0.0         0.0   \n",
       "189334         0.0         0.0         0.0         0.0         0.0   \n",
       "197659         0.0         0.0         0.0         0.0         0.0   \n",
       "204864         0.0         0.0         0.0         0.0         0.0   \n",
       "235105         0.0         0.0         0.0         8.0         8.0   \n",
       "248718         0.0         0.0         0.0         0.0         0.0   \n",
       "257204         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "ISBN    189205101X  1892065487  1895565014  1902852427  1932112138  \n",
       "UserID                                                              \n",
       "16795          0.0         0.0         0.0         0.0         0.0  \n",
       "23872          0.0         0.0         0.0         0.0         0.0  \n",
       "56399          0.0         7.0         0.0         0.0         0.0  \n",
       "60244          0.0         0.0         9.0         0.0         0.0  \n",
       "63714          0.0         0.0         0.0         0.0         0.0  \n",
       "69078          0.0         0.0         0.0         0.0         0.0  \n",
       "76626          0.0         0.0         0.0         0.0         0.0  \n",
       "78973          0.0         0.0         0.0         0.0         0.0  \n",
       "93047          0.0         0.0         0.0         7.0         0.0  \n",
       "95359          0.0         0.0         0.0         0.0         0.0  \n",
       "98391          0.0         9.0         0.0         0.0         9.0  \n",
       "100906         0.0         0.0         0.0         0.0         0.0  \n",
       "101851         9.0         0.0         0.0         0.0         0.0  \n",
       "114368         0.0         0.0         0.0         0.0         0.0  \n",
       "123883         0.0         0.0         0.0         0.0         0.0  \n",
       "129074         0.0         0.0         0.0         0.0         0.0  \n",
       "153662        10.0         0.0         0.0         0.0         0.0  \n",
       "171118         0.0         0.0         0.0         0.0         0.0  \n",
       "177458         0.0         0.0         0.0         3.0         0.0  \n",
       "185233         0.0         0.0         0.0         0.0         0.0  \n",
       "189334         0.0         0.0         0.0         0.0         0.0  \n",
       "197659         7.0         0.0        10.0         0.0         0.0  \n",
       "204864         0.0         0.0         0.0         0.0         0.0  \n",
       "235105         0.0         0.0         0.0         0.0         7.0  \n",
       "248718         0.0         0.0         0.0         0.0         0.0  \n",
       "257204         0.0         0.0         0.0         0.0         0.0  \n",
       "\n",
       "[26 rows x 1841 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ratings = popular_ratings(reviews_and_users, user_threshold=400, rating_threshold=400, book_threshold=1)\n",
    "rating_matrix = test_ratings.pivot(index='UserID',\n",
    "                                         columns='ISBN',\n",
    "                                         values= 'BookRating').fillna(0)\n",
    "print(test_ratings.shape)\n",
    "print(rating_matrix.shape)\n",
    "rating_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "84849af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16795</td>\n",
       "      <td>mechanicsville, maryland, usa</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23872</td>\n",
       "      <td>tulsa, oklahoma, usa</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56399</td>\n",
       "      <td>n/a, surrey, united kingdom</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60244</td>\n",
       "      <td>alvin, texas, usa</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63714</td>\n",
       "      <td>milton keynes, england, united kingdom</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>69078</td>\n",
       "      <td>new york, new york, usa</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>76626</td>\n",
       "      <td>london, england, united kingdom</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>78973</td>\n",
       "      <td>amadora, lisboa, portugal</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>93047</td>\n",
       "      <td>nashua, new hampshire, usa</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>95359</td>\n",
       "      <td>charleston, west virginia, usa</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>98391</td>\n",
       "      <td>morrow, georgia, usa</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100906</td>\n",
       "      <td>seattle, washington, usa</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>101851</td>\n",
       "      <td>keizer, oregon, usa</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>114368</td>\n",
       "      <td>mechanicsville, maryland, usa</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>123883</td>\n",
       "      <td>topeka, kansas, usa</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>129074</td>\n",
       "      <td>marietta, georgia, usa</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>153662</td>\n",
       "      <td>ft. stewart, georgia, usa</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>171118</td>\n",
       "      <td>toronto, ontario, canada</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>177458</td>\n",
       "      <td>ottawa, ontario, canada</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>185233</td>\n",
       "      <td>winnemucca, nevada, usa</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>189334</td>\n",
       "      <td>ottawa, ontario, canada</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>197659</td>\n",
       "      <td>indiana, pennsylvania, usa</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>204864</td>\n",
       "      <td>simi valley, california, usa</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>235105</td>\n",
       "      <td>st louis, missouri, usa</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>248718</td>\n",
       "      <td>hyde park, new york, usa</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User-ID                                Location   Age\n",
       "0     16795           mechanicsville, maryland, usa  47.0\n",
       "1     23872                    tulsa, oklahoma, usa  22.0\n",
       "2     56399             n/a, surrey, united kingdom  63.0\n",
       "3     60244                       alvin, texas, usa  47.0\n",
       "4     63714  milton keynes, england, united kingdom  29.0\n",
       "5     69078                 new york, new york, usa  42.0\n",
       "6     76626         london, england, united kingdom  38.0\n",
       "7     78973               amadora, lisboa, portugal  29.0\n",
       "8     93047              nashua, new hampshire, usa  52.0\n",
       "9     95359          charleston, west virginia, usa  33.0\n",
       "10    98391                    morrow, georgia, usa  52.0\n",
       "11   100906                seattle, washington, usa  34.0\n",
       "12   101851                     keizer, oregon, usa  29.0\n",
       "13   114368           mechanicsville, maryland, usa  33.0\n",
       "14   123883                     topeka, kansas, usa  18.0\n",
       "15   129074                  marietta, georgia, usa  51.0\n",
       "16   153662               ft. stewart, georgia, usa  44.0\n",
       "17   171118                toronto, ontario, canada  47.0\n",
       "18   177458                 ottawa, ontario, canada  29.0\n",
       "19   185233                 winnemucca, nevada, usa  31.0\n",
       "20   189334                 ottawa, ontario, canada  49.0\n",
       "21   197659              indiana, pennsylvania, usa  49.0\n",
       "22   204864            simi valley, california, usa  47.0\n",
       "23   235105                 st louis, missouri, usa  46.0\n",
       "24   248718                hyde park, new york, usa  43.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userid_list = rating_matrix.index.tolist()\n",
    "column_names = [\"UserID\", \"Location\", \"Age\"]\n",
    "sampled_users = pd.DataFrame(columns = column_names)\n",
    "sampled_users = users.loc[users['User-ID'].isin(userid_list)]\n",
    "sampled_users = sampled_users.reset_index()\n",
    "sampled_users = sampled_users.drop(['index'], axis=1)\n",
    "\n",
    "print(sampled_users.shape)\n",
    "sampled_users.head(-1)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2c672a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0971880107</td>\n",
       "      <td>Wild Animus</td>\n",
       "      <td>Rich Shapero</td>\n",
       "      <td>2004</td>\n",
       "      <td>Too Far</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0446310786</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>1988</td>\n",
       "      <td>Little Brown &amp;amp; Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0449005615</td>\n",
       "      <td>Seabiscuit: An American Legend</td>\n",
       "      <td>LAURA HILLENBRAND</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0553582747</td>\n",
       "      <td>From the Corner of His Eye</td>\n",
       "      <td>Dean Koontz</td>\n",
       "      <td>2001</td>\n",
       "      <td>Bantam Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>042518630X</td>\n",
       "      <td>Purity in Death</td>\n",
       "      <td>J.D. Robb</td>\n",
       "      <td>2002</td>\n",
       "      <td>Berkley Publishing Group</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                      Book-Title        Book-Author  \\\n",
       "0  0971880107                     Wild Animus       Rich Shapero   \n",
       "1  0446310786           To Kill a Mockingbird         Harper Lee   \n",
       "2  0449005615  Seabiscuit: An American Legend  LAURA HILLENBRAND   \n",
       "3  0553582747      From the Corner of His Eye        Dean Koontz   \n",
       "4  042518630X                 Purity in Death          J.D. Robb   \n",
       "\n",
       "   Year-Of-Publication                   Publisher  \n",
       "0                 2004                     Too Far  \n",
       "1                 1988  Little Brown &amp; Company  \n",
       "2                 2002            Ballantine Books  \n",
       "3                 2001                Bantam Books  \n",
       "4                 2002    Berkley Publishing Group  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_isbn_list = rating_matrix.columns.values.tolist()\n",
    "column_names = [\"ISBN\", \"BookTitle\", \"BookAuthor\", \"PublicationYear\", \"Publisher\"]\n",
    "sampled_books = pd.DataFrame(columns = column_names)\n",
    "sampled_books = books.loc[books['ISBN'].isin(book_isbn_list)]\n",
    "sampled_books = sampled_books.reset_index()\n",
    "sampled_books = sampled_books.drop(['index'], axis=1)\n",
    "sampled_books = sampled_books.drop(['Image-URL-S',\"Image-URL-M\",\"Image-URL-L\"], axis=1)\n",
    "\n",
    "\n",
    "sampled_books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cba490",
   "metadata": {},
   "source": [
    "The Data is more or less ready now to be used for a Collaborative Filtering Model.\n",
    "\n",
    "The Model I will go with is a KNN Model (K Nearest Neighbors) there is more information about the process below:\n",
    "\n",
    "In K Nearest Neighbors for collaborative filtering, we use the number of k people who most similar to the person we are looking for to find good recommendations. \n",
    "\n",
    "The best value for k depends on the problem. We use KNN with Means algorithm for building user-based recommender system. \n",
    "\n",
    "This algorithm takes into account the mean ratings of each user.\n",
    "We use cosine similarity measure to compute the closeness of users with each other.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00beff93",
   "metadata": {},
   "source": [
    "# Collaborative Filtering Using OOP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0db1c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f1abeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get neighbors of target user based on similarity measure.\n",
    "#find k nearest neighbors and use their ratings to recommend the items to the target user.\n",
    "\n",
    "#Because most of this code was borrowed, I took time to go in and document what I understood about it.\n",
    "\n",
    "\n",
    "\n",
    "class UserBasedCollaborativeFiltering():\n",
    "    \n",
    "    def __init__(self, users, books, ratings, k=10, max_rating=10.0):\n",
    "        self.users = users\n",
    "        self.users = self.users.reset_index()\n",
    "        self.users = self.users.drop(columns=['index'])\n",
    "        \n",
    "        self.books = books\n",
    "        \n",
    "        self.ratings = ratings\n",
    "        self.ratings = self.ratings.reset_index()\n",
    "        self.ratings = self.ratings.drop(columns=['UserID'])\n",
    "        \n",
    "        self.k = k\n",
    "        self.max_rating = max_rating\n",
    "    \n",
    "    \n",
    "    def normalize(self, dataframe):\n",
    "        #This method normalizes a DataFrame by subtracting the mean of each row from the entries in that row.\n",
    "        \"\"\" \n",
    "        row_sum_ratings: computes the sum of the ratings for each row.\n",
    "        non_zero_count: counts the number of non-zero entries in each row.\n",
    "        dataframe_mean: computes the mean of each row by dividing row_sum_ratings by non_zero_count.\n",
    "        self.normalized_ratings: subtracts dataframe_mean from dataframe along the rows.\n",
    "        \"\"\"\n",
    "    \n",
    "    \n",
    "        row_sum_ratings = dataframe.sum(axis=1) # sum entries of rows\n",
    "        non_zero_count = dataframe.astype(bool).sum(axis=1) # count non-zero entries of rows \n",
    "        \n",
    "        dataframe_mean = row_sum_ratings / non_zero_count # mean of rows\n",
    "        \n",
    "        self.normalized_ratings = dataframe.subtract(dataframe_mean, axis = 0) # subtract on rows(iteration over columns!)\n",
    "    \n",
    "    def compute_similarity(self, x, y):\n",
    "        \n",
    "        \"\"\"\n",
    "        This method computes the cosine similarity between two vectors x and y.\n",
    "        \n",
    "        np.dot(x, y) computes the dot product of x and y.\n",
    "        np.linalg.norm(x) computes the Euclidean norm (magnitude) of x.\n",
    "        np.linalg.norm(y) computes the Euclidean norm (magnitude) of y.\n",
    "        \n",
    "        The cosine similarity is then computed as the \n",
    "        dot product of x and y divided by the product of the Euclidean norms of x and y.\n",
    "        \"\"\"\n",
    "        \n",
    "        return np.dot(x, y)/ (np.linalg.norm(x) * np.linalg.norm(y))\n",
    "\n",
    "\n",
    "    def create_similarity_matrix(self):   \n",
    "        \"\"\"\n",
    "        This function computes the similarity between each pair of users in the system using book ratings.\n",
    "        In order to do this we initialize a numpy array to store the similarities outputted by --\n",
    "        --the compute_similarity function, for every pair of users.\n",
    "        It then reshapes this array into a DataFrame and returns it as the similarity matrix.\n",
    "        \"\"\"\n",
    "        \n",
    "        num_users = len(self.users)\n",
    "        similarity_array = np.array([self.compute_similarity(self.ratings.iloc[i,:], self.ratings.iloc[j,:])\n",
    "        for i in range(num_users) for j in range(num_users)])\n",
    "        similarity_matrix = pd.DataFrame(data = similarity_array.reshape(self.users.shape[0], self.users.shape[0]))\n",
    "        \n",
    "        return similarity_matrix\n",
    "\n",
    "    def get_neighbors(self, user_id, similarity_matrix):\n",
    "        \"\"\"\n",
    "        This function takes a user ID & an inputted similarity matrix & returns the indices of the k most similar users. \n",
    "        \n",
    "        To do this, find the index of the specified user in the users dataframe\n",
    "        and use this to extract the row from the similarity matrix corresponding to that user.\n",
    "        \n",
    "        It then sorts the similarities in decreasing order, takes the top k+1 values (excluding the similarity of the user to themselves), \n",
    "        and returns their indices.\n",
    "        \"\"\"\n",
    "        user_index = self.users.loc[self.users['User-ID'] == user_id].index.values[0]\n",
    "        user_similairities = similarity_matrix.iloc[user_index].values\n",
    "        temp_neighbors_index = user_similairities.argsort()[-(self.k + 1):][::-1]\n",
    "        neighbor_index = np.delete(temp_neighbors_index, np.where(temp_neighbors_index[user_index] == user_index))\n",
    "        \n",
    "        return neighbor_index    \n",
    "        \n",
    "    def score_item(self, user_id, neighbor_rating, neighbor_similarity, ratings):\n",
    "        \"\"\"\n",
    "        This function computes a score for each item in a set of recommended books for a given user.\n",
    "        \n",
    "        First, we take the user ID, the normalized ratings of the k most similar users, their similarity scores, and the full ratings matrix. \n",
    "        \n",
    "        It computes the mean rating for the active user (the user we are making recommendations for), \n",
    "        then computes the weighted sum of the ratings of the k most similar users, where the weights are the similarity scores. \n",
    "        It adds the active user's mean rating to this weighted sum to get the final score, which it returns as a dataframe.\n",
    "        \"\"\"\n",
    "        user_index = self.users.loc[self.users['User-ID'] == user_id].index.values[0]\n",
    "        active_user_mean_rating = np.mean(ratings.iloc[user_index, :])\n",
    "        score = np.dot(neighbor_similarity, neighbor_rating) + active_user_mean_rating\n",
    "        data = score.reshape(1, len(score))\n",
    "        columns = neighbor_rating.columns\n",
    "        \n",
    "        return pd.DataFrame(data= data , columns= columns)\n",
    "    \n",
    "    \n",
    "\n",
    "    def recommend(self, user_id):\n",
    "        \"\"\"\n",
    "        This function takes a user ID as input and returns a set of recommended books for that user. \n",
    "        \n",
    "        finds the index of the specified user in the users dataframe and extracts their ratings from the full ratings matrix.\n",
    "        It then identifies which books the user has not yet rated and stores their ISBNs in a list. \n",
    "        \n",
    "        We start to combine all of the previous functions to make this process work.\n",
    "        This first involves calling normalize() to normalize the ratings matrix,\n",
    "        \n",
    "        Then create_similarity_matrix() to compute the similarity matrix. \n",
    "        \n",
    "        get_neighbors() takes k most similar users and extracts their normalized ratings for the books that the active user has not yet rated. \n",
    "\n",
    "\n",
    "        score_item() to compute a score for each recommended book and returns the top k books with the highest scores. \n",
    "        \n",
    "        Finally, it extracts the details of the recommended books from the books dataframe and returns them as a dataframe.\n",
    "        \"\"\"\n",
    "        user_index = self.users.loc[self.users['User-ID'] == user_id].index.values[0]\n",
    "        user_ratings = rating_matrix.iloc[user_index]\n",
    "        recommendation_columns = []\n",
    "\n",
    "        for i in range(len(user_ratings.index)):\n",
    "            isbn = user_ratings.index[i]\n",
    "            rating = user_ratings.values[i]\n",
    "            if rating == 0.0:\n",
    "                recommendation_columns.append(isbn)\n",
    "\n",
    "        self.normalize(self.ratings)  \n",
    "        similarity_matrix = self.create_similarity_matrix()\n",
    "        neighbor_index = self.get_neighbors(user_id, similarity_matrix)\n",
    "        neighbor_rating = self.normalized_ratings.loc[neighbor_index][recommendation_columns]\n",
    "        neighbor_similarity = similarity_matrix[user_index].loc[neighbor_index]\n",
    "        recommendation_score = self.score_item(user_id, neighbor_rating, neighbor_similarity, self.ratings)\n",
    "        recommended_book_ISBNs = recommendation_score.stack().nlargest(self.k)\n",
    "        recommended_book_ISBNs = [recommended_book_ISBNs.index.values[i][1] for i in range(len(recommended_book_ISBNs))]\n",
    "        recommended_books = self.books.loc[self.books['ISBN'].isin(recommended_book_ISBNs)]\n",
    "\n",
    "        return recommended_books\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffb999d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_based_cf = UserBasedCollaborativeFiltering(sampled_users, sampled_books, rating_matrix)\n",
    "similarity_matrix = user_based_cf.create_similarity_matrix()\n",
    "\n",
    "user_id = 23872\n",
    "recommendations = user_based_cf.recommend(user_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb700909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0804106304</td>\n",
       "      <td>The Joy Luck Club</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1994</td>\n",
       "      <td>Prentice Hall (K-12)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0316666343</td>\n",
       "      <td>The Lovely Bones: A Novel</td>\n",
       "      <td>Alice Sebold</td>\n",
       "      <td>2002</td>\n",
       "      <td>Little, Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0061009059</td>\n",
       "      <td>One for the Money (Stephanie Plum Novels (Pape...</td>\n",
       "      <td>Janet Evanovich</td>\n",
       "      <td>1995</td>\n",
       "      <td>HarperTorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0399146431</td>\n",
       "      <td>The Bonesetter's Daughter</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>2001</td>\n",
       "      <td>Putnam Publishing Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0811802981</td>\n",
       "      <td>The Golden Mean: In Which the Extraordinary Co...</td>\n",
       "      <td>Nick Bantock</td>\n",
       "      <td>1993</td>\n",
       "      <td>Chronicle Books</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ISBN                                         Book-Title  \\\n",
       "7    0804106304                                  The Joy Luck Club   \n",
       "39   0316666343                          The Lovely Bones: A Novel   \n",
       "66   0061009059  One for the Money (Stephanie Plum Novels (Pape...   \n",
       "224  0399146431                          The Bonesetter's Daughter   \n",
       "255  0811802981  The Golden Mean: In Which the Extraordinary Co...   \n",
       "\n",
       "         Book-Author  Year-Of-Publication                Publisher  \n",
       "7            Amy Tan                 1994     Prentice Hall (K-12)  \n",
       "39      Alice Sebold                 2002            Little, Brown  \n",
       "66   Janet Evanovich                 1995              HarperTorch  \n",
       "224          Amy Tan                 2001  Putnam Publishing Group  \n",
       "255     Nick Bantock                 1993          Chronicle Books  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5e91c5",
   "metadata": {},
   "source": [
    "# My Thoughts with this Model: \n",
    "\n",
    "A glaring flaw exists within the design of this model:\n",
    "For every recommendation, you must find establish similarity between every single User.\n",
    "\n",
    "This becomes computationally more expensive the more users there are, and is not optimal for our massive Data Set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ac8f2f",
   "metadata": {},
   "source": [
    "# Item Based Collab. Filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d7478e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemBasedCollaborativeFiltering():    \n",
    "    def __init__(self, users, books, ratings, k=10, max_rating=10.0):\n",
    "        self.users = users\n",
    "        self.users = self.users.reset_index()\n",
    "        self.users = self.users.drop(columns=['index'])\n",
    "        \n",
    "        self.books = books\n",
    "        \n",
    "        self.ratings = ratings\n",
    "        self.ratings = self.ratings.reset_index()\n",
    "        self.ratings = self.ratings.drop(columns=['UserID'])\n",
    "        \n",
    "        self.k = k\n",
    "        self.max_rating = max_rating\n",
    "        \n",
    "        self.frequencies = {}\n",
    "        self.deviations = {}\n",
    "        \n",
    "    \n",
    "    def prepare_data(self):\n",
    "        \n",
    "        \"\"\"\n",
    "            A method which prepares the data for the algorithm.\n",
    "        It converts the ratings DataFrame into a list of dictionaries,\n",
    "        where each dictionary contains the ratings of a user for the items.\n",
    "                            Returns the list.\"\"\"\n",
    "        \n",
    "        user_indices = list(self.ratings.index.values)\n",
    "        \n",
    "        users_ratings = []\n",
    "        \n",
    "        for user_index in user_indices:\n",
    "            rated_book_indices = list(self.ratings.iloc[user_index].to_numpy().nonzero()[0])\n",
    "            users_ratings.append({user_index: dict(self.ratings[self.ratings.columns[rated_book_indices]].iloc[user_index])})\n",
    "    \n",
    "        self.users_ratings = users_ratings\n",
    "        \n",
    "        return self.users_ratings\n",
    "        \n",
    "        \n",
    "    def compute_deviations(self):\n",
    "        \n",
    "        \"\"\"\n",
    "         Computes the deviation of the ratings of each item from the ratings of the other items. \n",
    "             Populates two dictionaries:\n",
    "             self.frequencies: a dictionary that stores the number of times each pair of items has been rated together\n",
    "             \n",
    "             self.deviations: a dictionary that stores the average deviation of the ratings of each item from the ratings of the other items\n",
    "\n",
    "        \"\"\"\n",
    "        users_ratings = self.users_ratings\n",
    "        num_users = len(self.users)\n",
    "        \n",
    "        for i in range(num_users):\n",
    "            for ratings in self.users_ratings[i].values():\n",
    "                for item, rating in ratings.items():\n",
    "                    self.frequencies.setdefault(item, {})\n",
    "                    self.deviations.setdefault(item, {})\n",
    "                    \n",
    "                    for (item2, rating2) in ratings.items():\n",
    "                        if item != item2:\n",
    "                            self.frequencies[item].setdefault(item2, 0)\n",
    "                            self.deviations[item].setdefault(item2, 0.0)\n",
    "                            self.frequencies[item][item2] += 1\n",
    "                            self.deviations[item][item2] += rating - rating2\n",
    "            \n",
    "            for (item, ratings) in self.deviations.items():\n",
    "                for item2 in ratings:\n",
    "                    ratings[item2] /= self.frequencies[item][item2]\n",
    "    \n",
    "    \n",
    "    def slope_one_recommend(self, user_ratings):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function takes in user_ratings, \n",
    "        which is a dictionary where the keys are book IDs (ISBNs) and the values are the corresponding ratings given by the user.\n",
    "        \n",
    "        It computes recommendations for items that the user has not rated using a Slope One algorithm.\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        recommendations = {}\n",
    "        frequencies = {}\n",
    "        \n",
    "        #Looping through each item and rating in the user's input, \n",
    "        #then looping through each item and deviation in the deviation dictionary. \n",
    "        \n",
    "        for (user_item, user_rating) in user_ratings.items():\n",
    "        \n",
    "            for (diff_item, diff_ratings) in self.deviations.items():\n",
    "                \n",
    "                #If the current deviation dictionary item has not been rated by the user,\n",
    "                #but the current user input item has been rated,\n",
    "                #the function updates the recommendation dictionary with a weighted average \n",
    "\n",
    "                if diff_item not in user_ratings and user_item in self.deviations[diff_item]:\n",
    "                    freq = self.frequencies[diff_item][user_item]\n",
    "                    recommendations.setdefault(diff_item, 0.0)\n",
    "                    frequencies.setdefault(diff_item, 0)\n",
    "        \n",
    "                    recommendations[diff_item] += (diff_ratings[user_item] + user_rating) * freq\n",
    "                    frequencies[diff_item] += freq\n",
    "        \n",
    "        recommendations = [(k, v / frequencies[k]) for (k, v) in recommendations.items()]\n",
    "        \n",
    "        recommendations.sort(key=lambda ratings: ratings[1], reverse = True)\n",
    "        \n",
    "        #returns a list of recommendations, sorted by descending order of recommendation score\n",
    "        return recommendations\n",
    "    \n",
    "    \n",
    "    def recommend(self, recommendations):\n",
    "        \n",
    "        \"\"\" \n",
    "            takes in a list of recommendations and returns the top k recommendations,\n",
    "        where k is the value passed when initializing the Class.\n",
    "        \"\"\"\n",
    "        top_k_recommendations = recommendations[: self.k]\n",
    "        \n",
    "        isbns = [recommendation[0] for recommendation in top_k_recommendations]\n",
    "        \n",
    "        recommended_books = [self.books.loc[self.books['ISBN'] == isbn] for isbn in isbns]\n",
    "        return pd.concat(recommended_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2ca717a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User-ID</th>\n",
       "      <td>23872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>tulsa, oklahoma, usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             1\n",
       "User-ID                  23872\n",
       "Location  tulsa, oklahoma, usa\n",
       "Age                       22.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_based_cf = ItemBasedCollaborativeFiltering(sampled_users, sampled_books, rating_matrix)\n",
    "users_ratings = item_based_cf.prepare_data()\n",
    "item_based_cf.compute_deviations()\n",
    "\n",
    "user_index = 1\n",
    "pd.DataFrame(sampled_users.iloc[user_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7265d5e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>0312251947</td>\n",
       "      <td>Naked Came the Phoenix: A Serial Novel</td>\n",
       "      <td>Marcia Talley</td>\n",
       "      <td>2001</td>\n",
       "      <td>St. Martin's Minotaur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>0373790988</td>\n",
       "      <td>Slippery When Wet: Under the Covers (Harlequin...</td>\n",
       "      <td>Kristin Hardy</td>\n",
       "      <td>2003</td>\n",
       "      <td>Harlequin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>0515133868</td>\n",
       "      <td>Once Upon a Kiss</td>\n",
       "      <td>Nora Roberts</td>\n",
       "      <td>2002</td>\n",
       "      <td>Jove Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0140183515</td>\n",
       "      <td>Just So Stories (Penguin Twentieth-Century Cla...</td>\n",
       "      <td>Rudyard Kipling</td>\n",
       "      <td>1990</td>\n",
       "      <td>Penguin Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>1556342616</td>\n",
       "      <td>GURPS Discworld</td>\n",
       "      <td>Phil Masters</td>\n",
       "      <td>1998</td>\n",
       "      <td>Steve Jackson Games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>0345335945</td>\n",
       "      <td>Camber of Culdi #1 (Legends of Camber of Culdi)</td>\n",
       "      <td>Katherine Kurtz</td>\n",
       "      <td>1982</td>\n",
       "      <td>Del Rey Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>0345347633</td>\n",
       "      <td>Deryni Rising (Chronicles of the Deryni)</td>\n",
       "      <td>Katherine Kurtz</td>\n",
       "      <td>1990</td>\n",
       "      <td>Del Rey Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>0553560220</td>\n",
       "      <td>Illusion</td>\n",
       "      <td>Paula Volsky</td>\n",
       "      <td>1993</td>\n",
       "      <td>Bantam Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>0553561189</td>\n",
       "      <td>Mistress of the Empire</td>\n",
       "      <td>Raymond E. Feist</td>\n",
       "      <td>1993</td>\n",
       "      <td>Bantam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>185326119X</td>\n",
       "      <td>The Jungle Book (Wordsworth Collection)</td>\n",
       "      <td>Rudyard Kipling</td>\n",
       "      <td>1998</td>\n",
       "      <td>NTC/Contemporary Publishing Company</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ISBN                                         Book-Title  \\\n",
       "1047  0312251947             Naked Came the Phoenix: A Serial Novel   \n",
       "1444  0373790988  Slippery When Wet: Under the Covers (Harlequin...   \n",
       "785   0515133868                                   Once Upon a Kiss   \n",
       "514   0140183515  Just So Stories (Penguin Twentieth-Century Cla...   \n",
       "1506  1556342616                                    GURPS Discworld   \n",
       "1825  0345335945    Camber of Culdi #1 (Legends of Camber of Culdi)   \n",
       "1410  0345347633           Deryni Rising (Chronicles of the Deryni)   \n",
       "449   0553560220                                           Illusion   \n",
       "1318  0553561189                             Mistress of the Empire   \n",
       "798   185326119X            The Jungle Book (Wordsworth Collection)   \n",
       "\n",
       "           Book-Author  Year-Of-Publication  \\\n",
       "1047     Marcia Talley                 2001   \n",
       "1444     Kristin Hardy                 2003   \n",
       "785       Nora Roberts                 2002   \n",
       "514    Rudyard Kipling                 1990   \n",
       "1506      Phil Masters                 1998   \n",
       "1825   Katherine Kurtz                 1982   \n",
       "1410   Katherine Kurtz                 1990   \n",
       "449       Paula Volsky                 1993   \n",
       "1318  Raymond E. Feist                 1993   \n",
       "798    Rudyard Kipling                 1998   \n",
       "\n",
       "                                Publisher  \n",
       "1047                St. Martin's Minotaur  \n",
       "1444                            Harlequin  \n",
       "785                            Jove Books  \n",
       "514                         Penguin Books  \n",
       "1506                  Steve Jackson Games  \n",
       "1825                        Del Rey Books  \n",
       "1410                        Del Rey Books  \n",
       "449                          Bantam Books  \n",
       "1318                               Bantam  \n",
       "798   NTC/Contemporary Publishing Company  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations = item_based_cf.slope_one_recommend(users_ratings[user_index][user_index])\n",
    "item_based_cf.recommend(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d6c005d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16795</td>\n",
       "      <td>mechanicsville, maryland, usa</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23872</td>\n",
       "      <td>tulsa, oklahoma, usa</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56399</td>\n",
       "      <td>n/a, surrey, united kingdom</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60244</td>\n",
       "      <td>alvin, texas, usa</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63714</td>\n",
       "      <td>milton keynes, england, united kingdom</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>69078</td>\n",
       "      <td>new york, new york, usa</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>76626</td>\n",
       "      <td>london, england, united kingdom</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>78973</td>\n",
       "      <td>amadora, lisboa, portugal</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>93047</td>\n",
       "      <td>nashua, new hampshire, usa</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>95359</td>\n",
       "      <td>charleston, west virginia, usa</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>98391</td>\n",
       "      <td>morrow, georgia, usa</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100906</td>\n",
       "      <td>seattle, washington, usa</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>101851</td>\n",
       "      <td>keizer, oregon, usa</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>114368</td>\n",
       "      <td>mechanicsville, maryland, usa</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>123883</td>\n",
       "      <td>topeka, kansas, usa</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>129074</td>\n",
       "      <td>marietta, georgia, usa</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>153662</td>\n",
       "      <td>ft. stewart, georgia, usa</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>171118</td>\n",
       "      <td>toronto, ontario, canada</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>177458</td>\n",
       "      <td>ottawa, ontario, canada</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>185233</td>\n",
       "      <td>winnemucca, nevada, usa</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>189334</td>\n",
       "      <td>ottawa, ontario, canada</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>197659</td>\n",
       "      <td>indiana, pennsylvania, usa</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>204864</td>\n",
       "      <td>simi valley, california, usa</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>235105</td>\n",
       "      <td>st louis, missouri, usa</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>248718</td>\n",
       "      <td>hyde park, new york, usa</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>257204</td>\n",
       "      <td>akron, ohio, usa</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User-ID                                Location   Age\n",
       "0     16795           mechanicsville, maryland, usa  47.0\n",
       "1     23872                    tulsa, oklahoma, usa  22.0\n",
       "2     56399             n/a, surrey, united kingdom  63.0\n",
       "3     60244                       alvin, texas, usa  47.0\n",
       "4     63714  milton keynes, england, united kingdom  29.0\n",
       "5     69078                 new york, new york, usa  42.0\n",
       "6     76626         london, england, united kingdom  38.0\n",
       "7     78973               amadora, lisboa, portugal  29.0\n",
       "8     93047              nashua, new hampshire, usa  52.0\n",
       "9     95359          charleston, west virginia, usa  33.0\n",
       "10    98391                    morrow, georgia, usa  52.0\n",
       "11   100906                seattle, washington, usa  34.0\n",
       "12   101851                     keizer, oregon, usa  29.0\n",
       "13   114368           mechanicsville, maryland, usa  33.0\n",
       "14   123883                     topeka, kansas, usa  18.0\n",
       "15   129074                  marietta, georgia, usa  51.0\n",
       "16   153662               ft. stewart, georgia, usa  44.0\n",
       "17   171118                toronto, ontario, canada  47.0\n",
       "18   177458                 ottawa, ontario, canada  29.0\n",
       "19   185233                 winnemucca, nevada, usa  31.0\n",
       "20   189334                 ottawa, ontario, canada  49.0\n",
       "21   197659              indiana, pennsylvania, usa  49.0\n",
       "22   204864            simi valley, california, usa  47.0\n",
       "23   235105                 st louis, missouri, usa  46.0\n",
       "24   248718                hyde park, new york, usa  43.0\n",
       "25   257204                        akron, ohio, usa  32.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sampled_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6adde07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User-ID</th>\n",
       "      <td>257204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>akron, ohio, usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        25\n",
       "User-ID             257204\n",
       "Location  akron, ohio, usa\n",
       "Age                   32.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_index = 25\n",
    "pd.DataFrame(sampled_users.iloc[user_index])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "39e29bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0385492081</td>\n",
       "      <td>Into Thin Air : A Personal Account of the Mt. ...</td>\n",
       "      <td>JON KRAKAUER</td>\n",
       "      <td>1998</td>\n",
       "      <td>Anchor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0312243022</td>\n",
       "      <td>The Hours : A Novel</td>\n",
       "      <td>Michael Cunningham</td>\n",
       "      <td>2000</td>\n",
       "      <td>Picador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0449907481</td>\n",
       "      <td>A Thousand Acres (Ballantine Reader's Circle)</td>\n",
       "      <td>JANE SMILEY</td>\n",
       "      <td>1992</td>\n",
       "      <td>Ballantine Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>0440404193</td>\n",
       "      <td>Are You There God?  It's Me, Margaret</td>\n",
       "      <td>JUDY BLUME</td>\n",
       "      <td>1971</td>\n",
       "      <td>Yearling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>0440472431</td>\n",
       "      <td>Ramona and Her Mother (Ramona Quimby (Paperback))</td>\n",
       "      <td>Beverly Cleary</td>\n",
       "      <td>1980</td>\n",
       "      <td>Bantam Doubleday Dell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>0440802458</td>\n",
       "      <td>Egypt Game</td>\n",
       "      <td>Zilpha Keatley Snyder</td>\n",
       "      <td>1991</td>\n",
       "      <td>Bantam Doubleday Dell Publishing Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>1558538445</td>\n",
       "      <td>I Hope You Dance</td>\n",
       "      <td>Mark D. Sanders</td>\n",
       "      <td>2000</td>\n",
       "      <td>Rutledge Hill Press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>0440498058</td>\n",
       "      <td>A Wrinkle In Time</td>\n",
       "      <td>MADELEINE L'ENGLE</td>\n",
       "      <td>1998</td>\n",
       "      <td>Yearling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>0553211285</td>\n",
       "      <td>The Adventures of Tom Sawyer (Adventures of To...</td>\n",
       "      <td>MARK TWAIN</td>\n",
       "      <td>1995</td>\n",
       "      <td>Bantam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>0307010856</td>\n",
       "      <td>The Monster at the End of This Book</td>\n",
       "      <td>JON STONE</td>\n",
       "      <td>2003</td>\n",
       "      <td>Golden Books</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ISBN                                         Book-Title  \\\n",
       "153   0385492081  Into Thin Air : A Personal Account of the Mt. ...   \n",
       "122   0312243022                                The Hours : A Novel   \n",
       "54    0449907481      A Thousand Acres (Ballantine Reader's Circle)   \n",
       "722   0440404193              Are You There God?  It's Me, Margaret   \n",
       "857   0440472431  Ramona and Her Mother (Ramona Quimby (Paperback))   \n",
       "1320  0440802458                                         Egypt Game   \n",
       "730   1558538445                                   I Hope You Dance   \n",
       "701   0440498058                                  A Wrinkle In Time   \n",
       "780   0553211285  The Adventures of Tom Sawyer (Adventures of To...   \n",
       "728   0307010856                The Monster at the End of This Book   \n",
       "\n",
       "                Book-Author  Year-Of-Publication  \\\n",
       "153            JON KRAKAUER                 1998   \n",
       "122      Michael Cunningham                 2000   \n",
       "54              JANE SMILEY                 1992   \n",
       "722              JUDY BLUME                 1971   \n",
       "857          Beverly Cleary                 1980   \n",
       "1320  Zilpha Keatley Snyder                 1991   \n",
       "730         Mark D. Sanders                 2000   \n",
       "701       MADELEINE L'ENGLE                 1998   \n",
       "780              MARK TWAIN                 1995   \n",
       "728               JON STONE                 2003   \n",
       "\n",
       "                                   Publisher  \n",
       "153                                   Anchor  \n",
       "122                                  Picador  \n",
       "54                          Ballantine Books  \n",
       "722                                 Yearling  \n",
       "857                    Bantam Doubleday Dell  \n",
       "1320  Bantam Doubleday Dell Publishing Group  \n",
       "730                      Rutledge Hill Press  \n",
       "701                                 Yearling  \n",
       "780                                   Bantam  \n",
       "728                             Golden Books  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations = item_based_cf.slope_one_recommend(users_ratings[user_index][user_index])\n",
    "item_based_cf.recommend(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5bae2a",
   "metadata": {},
   "source": [
    "# Content Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bae39e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import sigmoid_kernel\n",
    "\n",
    "class ContentBasedFiltering():\n",
    "    \n",
    "    def __init__(self, books, ratings, k = 10):\n",
    "        self.ratings = ratings\n",
    "        self.books = self.prepare_data(books)\n",
    "        self.tfidf_matrix = self.create_embedding_matrix()\n",
    "        self.sigmoid = self.create_kernel()\n",
    "        self.indices = self.create_indices()\n",
    "        self.k = k\n",
    "        \n",
    "        \n",
    "    def clean(self, text, combine=False):\n",
    "        text = text.lower()\n",
    "        text = re.sub('[^a-z0-9 ]', '', text)\n",
    "        \n",
    "        if combine:\n",
    "            return ''.join(t.replace(' ', '') for t in text).strip()\n",
    "        \n",
    "        return text.strip()\n",
    "    \n",
    "    \n",
    "    def prepare_data(self, books, rating_threshold = 2):\n",
    "        \n",
    "        # select books that has been rated\n",
    "        rated_books = books[books.ISBN.isin(ratings.ISBN)]\n",
    "        \n",
    "        # remove duplicates based on bookTitle\n",
    "        unique_books = rated_books.drop_duplicates(subset = ['Book-Title'], keep = False)\n",
    "        \n",
    "        # if rating count of a book > rating_threshold, then the book will be selected.\n",
    "        popular_ISBN = list(self.ratings.ISBN.value_counts()[self.ratings.ISBN.value_counts() >= rating_threshold].index)\n",
    "        \n",
    "        # Only keep the books that its rating count is > rating_threshold; this means that it is popular.\n",
    "        popular_books = unique_books[unique_books.ISBN.isin(popular_ISBN)]\n",
    "        \n",
    "        popular_books['BookTitleClean'] = popular_books['Book-Title'].map(lambda x: self.clean(x, combine=False))\n",
    "        \n",
    "        popular_books['spaghetti'] = popular_books['BookTitleClean']\n",
    "        \n",
    "        return popular_books \n",
    "    \n",
    "    \n",
    "    def create_embedding_matrix(self):\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        \n",
    "        self.books['spaghetti'] = self.books['spaghetti'].fillna('')\n",
    "        self.books = self.books.reset_index()\n",
    "\n",
    "        tfidf_vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(self.books['spaghetti'])\n",
    "        print('tf-idf embedding matrix shape = ' + str(tfidf_matrix.shape))\n",
    "        \n",
    "        return tfidf_matrix\n",
    "    \n",
    "    def create_kernel(self):\n",
    "        return sigmoid_kernel(self.tfidf_matrix, self.tfidf_matrix)\n",
    "        \n",
    "    \n",
    "    def create_indices(self):\n",
    "        return pd.Series(self.books.index, index = self.books['Book-Title']).drop_duplicates()\n",
    "    \n",
    "    \n",
    "    def recommend(self, query):\n",
    "        \n",
    "        idx = self.indices[query]\n",
    "\n",
    "        sigmoid_scores = list(enumerate(self.sigmoid[idx]))\n",
    "        sigmoid_scores = sorted(sigmoid_scores, key=lambda x: x[1], reverse=True)\n",
    "        sigmoid_scores = sigmoid_scores[1: self.k + 1]\n",
    "        \n",
    "        book_indices = [i[0] for i in sigmoid_scores]\n",
    "        \n",
    "        recommendations =  pd.DataFrame(self.books.iloc[book_indices])\n",
    "        recommendations = recommendations.drop(columns=['index', 'BookTitleClean', 'spaghetti'])\n",
    "        \n",
    "        return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7df6bfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-idf embedding matrix shape = (1796, 2910)\n"
     ]
    }
   ],
   "source": [
    "content_based_cf = ContentBasedFiltering(sampled_books, test_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "19e9e337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>0515132292</td>\n",
       "      <td>Wild</td>\n",
       "      <td>Lori Foster</td>\n",
       "      <td>2002</td>\n",
       "      <td>Jove Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>1551668777</td>\n",
       "      <td>So Wild A Heart</td>\n",
       "      <td>Candace Camp</td>\n",
       "      <td>2002</td>\n",
       "      <td>Mira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>0843953004</td>\n",
       "      <td>Wild Desire</td>\n",
       "      <td>Phoebe Conn</td>\n",
       "      <td>2003</td>\n",
       "      <td>Leisure Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0971880107</td>\n",
       "      <td>Wild Animus</td>\n",
       "      <td>Rich Shapero</td>\n",
       "      <td>2004</td>\n",
       "      <td>Too Far</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>0399149279</td>\n",
       "      <td>Wild Pitch</td>\n",
       "      <td>Mike Lupica</td>\n",
       "      <td>2002</td>\n",
       "      <td>Putnam Publishing Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>0743437128</td>\n",
       "      <td>Wild Orchids : A Novel</td>\n",
       "      <td>Jude Deveraux</td>\n",
       "      <td>2003</td>\n",
       "      <td>Atria Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>0380812037</td>\n",
       "      <td>On a Wild Night (Cynster Novels)</td>\n",
       "      <td>Stephanie Laurens</td>\n",
       "      <td>2002</td>\n",
       "      <td>Avon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>0373240880</td>\n",
       "      <td>Waiting For Nick  (Those Wild Ukrainians) (Sil...</td>\n",
       "      <td>Nora Roberts</td>\n",
       "      <td>1997</td>\n",
       "      <td>Silhouette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>0671769316</td>\n",
       "      <td>NEW ROADSIDE AMERICA : THE MODERN TRAVELER'S G...</td>\n",
       "      <td>Doug Kirby</td>\n",
       "      <td>1992</td>\n",
       "      <td>Fireside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0446310786</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>1988</td>\n",
       "      <td>Little Brown &amp;amp; Company</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ISBN                                         Book-Title  \\\n",
       "1208  0515132292                                               Wild   \n",
       "954   1551668777                                    So Wild A Heart   \n",
       "1541  0843953004                                        Wild Desire   \n",
       "0     0971880107                                        Wild Animus   \n",
       "1671  0399149279                                         Wild Pitch   \n",
       "1206  0743437128                             Wild Orchids : A Novel   \n",
       "428   0380812037                   On a Wild Night (Cynster Novels)   \n",
       "843   0373240880  Waiting For Nick  (Those Wild Ukrainians) (Sil...   \n",
       "452   0671769316  NEW ROADSIDE AMERICA : THE MODERN TRAVELER'S G...   \n",
       "1     0446310786                              To Kill a Mockingbird   \n",
       "\n",
       "            Book-Author  Year-Of-Publication                   Publisher  \n",
       "1208        Lori Foster                 2002                  Jove Books  \n",
       "954        Candace Camp                 2002                        Mira  \n",
       "1541        Phoebe Conn                 2003               Leisure Books  \n",
       "0          Rich Shapero                 2004                     Too Far  \n",
       "1671        Mike Lupica                 2002     Putnam Publishing Group  \n",
       "1206      Jude Deveraux                 2003                 Atria Books  \n",
       "428   Stephanie Laurens                 2002                        Avon  \n",
       "843        Nora Roberts                 1997                  Silhouette  \n",
       "452          Doug Kirby                 1992                    Fireside  \n",
       "1            Harper Lee                 1988  Little Brown &amp; Company  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Query = \"Wild\"\n",
    "content_based_cf.recommend(Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6aec0255",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Lori Foster'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Lori Foster'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [68]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m author \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLori Foster\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcontent_based_cf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecommend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauthor\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [57]\u001b[0m, in \u001b[0;36mContentBasedFiltering.recommend\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecommend\u001b[39m(\u001b[38;5;28mself\u001b[39m, query):\n\u001b[0;32m---> 68\u001b[0m     idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     70\u001b[0m     sigmoid_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid[idx]))\n\u001b[1;32m     71\u001b[0m     sigmoid_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(sigmoid_scores, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1069\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Lori Foster'"
     ]
    }
   ],
   "source": [
    "author = \"Lori Foster\"\n",
    "content_based_cf.recommend(author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e9d967d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Kill'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Kill'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [72]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m Publisher \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJove Books\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcontent_based_cf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecommend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauthor\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [57]\u001b[0m, in \u001b[0;36mContentBasedFiltering.recommend\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecommend\u001b[39m(\u001b[38;5;28mself\u001b[39m, query):\n\u001b[0;32m---> 68\u001b[0m     idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     70\u001b[0m     sigmoid_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid[idx]))\n\u001b[1;32m     71\u001b[0m     sigmoid_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(sigmoid_scores, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1069\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Kill'"
     ]
    }
   ],
   "source": [
    "Publisher = \"Jove Books\"\n",
    "content_based_cf.recommend(author)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61790b43",
   "metadata": {},
   "source": [
    "# Final Thoughts / Conclusions\n",
    "\n",
    "The scope of this project was to implement a working recommender system, based on traditional models. This mainly was done to develop a deeper understanding of the Algorithmic processes involved with this kind of work, while assessing which would be more useful for a given scenario. All three models work, but have slightly different alterations which give them an interesting Dynamic. I will rank them and give my explanation for this below:\n",
    "\n",
    "1. Item-To-Item Collaborative Filtering works the best with the Book-Crossing Dataset because it finds similarities between ratings, not users. This serves as an advantage, because assessing recommendations becomes computationally expensive the more users you have. In short, you can recommend a lot of books, while computation time stays low.   \n",
    "\n",
    "\n",
    "\n",
    "1. A unique advantage for Content-Based Filtering is that it can work when not a lot is known about the data. For instance, you can search for titles or Genres and get reasonable results. The only downside here is that, to take full advantage of its capabilities, you need quality features. For instance, my attempts at recommending Authors failed. This may have worked better if in my preprocessing phase, I spent more time looking over the Book-Author column, weeding out duplicates or other anomalies. \n",
    "\n",
    "\n",
    "\n",
    "1. Lastly, I rank User based filtering in third place, because I could not make full usage of this algorithm. User to User works best when a substantial amount of overlap comes into play, which, in my Data Analysis file, I found with careful digging. In my Analysis I found a 'popularity' metric can make quick assessments in which some Books are more favorable to recommend. This works in an 'item-to-item' context, but to truly personalize this for every user requires skills I currently do not possess.\n",
    "\n",
    "\n",
    "As stated, this project started because I wanted to directly engage with the math, while finding effective ways to program them. I consider this a success, but it wouldn't be possible without my sources. In these you'll find code I used to analyze, which inspired the process I undertook. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b84af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "132777df",
   "metadata": {},
   "source": [
    "# Citations\n",
    "\n",
    "1. https://towardsdatascience.com/my-journey-to-building-book-recommendation-system-5ec959c41847\n",
    "1. https://surprise.readthedocs.io/en/stable/knn_inspired.html\n",
    "1. https://towardsdatascience.com/user-user-collaborative-filtering-for-jokes-recommendation-b6b1e4ec8642\n",
    "1. https://towardsdatascience.com/my-journey-to-building-book-recommendation-system-5ec959c41847\n",
    "1. https://github.com/tttgm/fellowshipai/tree/master\n",
    "1. https://github.com/mohsenMahmoodzadeh/Book-Crossing-Recommender-System\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16042f09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
